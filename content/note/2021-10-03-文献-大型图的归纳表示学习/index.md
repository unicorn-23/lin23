---
title: 文献-大型图的归纳表示学习
author: Lin Gui
date: '2021-10-03'
slug: 文献-大型图的归纳表示学习
categories:
  - 学习
tags:
  - 文献
---

[大型图的归纳表示学习](https://arxiv.org/pdf/1706.02216v2.pdf)，decagon文章中新的图形自动编码器方法



## **Inductive Representation Learning on Large Graphs**

### 摘要

在从内容推荐到识别蛋白质功能的各种预测任务中，大型图中节点的低维embeddings被证明是非常有用的。然而，大多数现有的方法都要求在嵌入训练期间图中的所有节点都存在；这些以前的方法本质上是转换的，不能自然地推广到看不见的节点。

这里我们介绍GraphSAGE，这是一个通用归纳框架，它利用节点特征信息（例如，文本属性）高效地为以前看不见的数据生成节点嵌入。我们学习的不是为每个节点训练单个嵌入，而是通过从节点的局部邻域采样和聚合特征来生成嵌入的函数。我们的算法在三个归纳节点分类基准上优于强基线：我们基于引文和Reddit post数据对进化信息图中的不可见节点进行分类，并证明我们的算法使用蛋白质-蛋白质相互作用的多图数据集推广到完全不可见的图。

### Introduction

大图中节点的低维向量嵌入已被证明非常有用，可作为各种预测和图分析任务的特征输入。节点嵌入方法的**基本思想是使用降维技术将节点邻域的高维信息提取到稠密向量嵌入中。然后，这些节点嵌入可以反馈给下游机器学习系统，并帮助完成节点分类、聚类和链接预测等任务**。

然而，以前的工作主要集中在从单个固定图嵌入节点，许多实际应用需要为看不见的节点或全新（子）图快速生成嵌入。这种归纳能力对于高通量生产机器学习系统至关重要，该系统在不断变化的图形上运行，并不断遇到看不见的节点（例如Reddit上的帖子、用户和Youtube上的视频）。生成节点嵌入的归纳方法也有助于在具有相同特征形式的图之间进行泛化：例如，可以在从模型生物衍生的蛋白质-蛋白质相互作用图上训练嵌入生成器，然后使用经过训练的模型轻松地为收集到的新生物数据生成节点嵌入。

与transductive设置相比，归纳节点嵌入问题尤其困难，因为推广到不可见节点需要将新观察到的子图与算法已经优化的节点嵌入“对齐”。归纳框架必须学会识别节点邻域的结构属性，这些属性揭示了节点在图中的局部角色及其全局位置。

大多数现有的生成节点嵌入的方法本质上是转换的。这些方法中的大多数使用基于矩阵分解的目标直接优化每个节点的嵌入，并且不会自然地推广到看不见的数据，因为它们在单个固定图中对节点进行预测[5,11,23,28,35,36,37,39]。这些方法可以修改为在归纳设置下操作（例如，[28]），但这些修改往往在计算上很昂贵，需要在进行新预测之前进行额外的梯度下降。最近也有使用卷积算子学习图结构的方法，这些方法有望成为嵌入方法[17]。到目前为止，图卷积网络（GCN）仅应用于具有固定图的跨导设置[17,18]。在这项工作中，我们将GCN扩展到归纳无监督学习的任务，并提出了一个框架，该框架将GCN方法推广到使用可训练的聚合函数（除了简单的卷积）。

### 目前的工作。

我们提出了一个通用的框架，称为GraphSAGE（样本和聚合），用于归纳节点嵌入。与基于矩阵分解的嵌入方法不同，我们利用节点特征（例如，文本属性、节点配置文件信息、节点度）来学习可推广到不可见节点的嵌入函数。通过在学习算法中加入节点特征，我们可以同时学习每个节点邻域的拓扑结构以及节点特征在邻域中的分布。虽然我们关注特征丰富的图形（例如，具有文本属性的引用数据、具有功能/分子标记的生物数据），但我们的方法也可以利用所有图形中存在的结构特征（例如，节点度）。

因此，我们的算法也适用于没有节点特征的图。我们不是为每个节点训练一个不同的嵌入向量，而是训练一组聚合器函数，学习从节点的局部邻域聚合特征信息（图1）。每个聚合器函数聚合来自给定节点的不同跳数或搜索深度的信息。在测试或推理时，我们使用经过训练的系统通过应用学习的聚合函数为完全看不见的节点生成嵌入。根据之前关于生成节点嵌入的工作，我们设计了一个无监督损失函数，该函数允许图形图像在没有特定任务监督的情况下进行训练。我们还表明，图形图像可以在完全监督的方式下进行训练。

我们在三个节点分类基准上评估了我们的算法，这些基准测试GraphSAGE在看不见的数据上生成有用嵌入的能力。我们使用了两个基于引文数据和Reddit post数据（分别预测论文和帖子类别）的进化文档图，以及一个基于蛋白质-蛋白质相互作用数据集（预测蛋白质功能）的多图综合实验。使用这些基准测试，我们证明了我们的方法能够有效地为看不见的节点生成表示，并且在很大程度上优于相关基线：跨域，与单独使用节点特征相比，我们的监督方法将分类F1分数平均提高了51%，并且GraphSAGE始终优于强大的转换基线[28]，尽管采用了该基线∼在看不见的节点上运行的时间延长100倍。我们还表明，与受图卷积网络启发的聚合器相比，我们提出的新聚合器架构提供了显著的收益（平均7.4%）[17]。最后，我们探讨了我们方法的表达能力，并通过理论分析表明，GraphSAGE能够学习关于节点在图中的角色的结构信息，尽管它本质上是基于特征的（第5节）。

### 相关工作

我们的算法在概念上与以前的节点嵌入方法、图上学习的一般监督方法以及将卷积神经网络应用于图结构数据的最新进展有关。

**基于因子分解的嵌入方法**

最近有许多节点嵌入方法使用随机游走统计和基于矩阵分解的学习目标来学习低维嵌入[5,11,28,35,36]。这些方法还与更为经典的光谱聚类方法[23]、多维缩放方法[19]以及PageRank算法[25]密切相关。由于这些嵌入算法直接为单个节点训练节点嵌入，因此它们本质上是跨导的，并且至少需要昂贵的额外训练（例如，通过随机梯度下降）来对新节点进行预测。

此外，对于这些方法中的许多方法（例如，[11,28,35,36]），目标函数对嵌入的正交变换是不变的，这意味着嵌入空间不会在图之间自然泛化，并且在重新训练期间会漂移。这种趋势的一个显著例外是Yang等人[40]引入的Planetoid-I算法，它是一种基于归纳、嵌入的半监督学习方法。然而，Planetoid-I在推理过程中不使用任何图形结构信息；相反，它使用图形结构作为训练期间正则化的一种形式。与以前的方法不同，我们利用特征信息来训练模型，为看不见的节点生成嵌入。

**图上的监督学习**

除了节点嵌入方法，还有大量关于图结构数据的监督学习的文献。这包括多种基于内核的方法，其中图形的特征向量来自各种图形内核（参见[32]和其中的参考文献）。最近也有一些神经网络方法用于图形结构上的监督学习[7,10,21,31]。我们的方法在概念上受到许多算法的启发。然而，尽管这些以前的方法试图对整个图（或子图）进行分类，但这项工作的重点是为单个节点生成有用的表示。

**图卷积网络**

近年来，已经提出了几种用于在图上学习的卷积神经网络结构（例如，[4,9,8,17,24]）。这些方法中的大多数都不适用于大型图，或者设计用于整个图分类（或两者兼而有之）[4,9,8,24]。然而，我们的方法与Kipf等人提出的图卷积网络（GCN）密切相关[17,18]。原始的GCN算法[17]设计用于transductive环境中的半监督学习，精确算法要求在训练过程中已知完整的图拉普拉斯算子。我们算法的一个简单变体可以被视为GCN框架对归纳设置的扩展，我们在第3.3节中重新讨论了这一点。

### Proposed method: GraphSAGE

我们的方法背后的关键思想是，我们学习如何从节点的局部邻域（例如，附近节点的度或文本属性）聚合特征信息。我们首先描述GraphSAGE嵌入生成（即前向传播）算法，该算法在假定GraphSAGE模型参数已经学习的情况下为节点生成嵌入（第3.1节）。然后，我们描述了如何使用标准随机梯度下降和反向传播技术学习图形图像模型参数（第3.2节）。

**3.1嵌入生成（即前向传播）算法**

在本节中，我们描述了嵌入生成或前向传播算法（算法1），该算法假设模型已经过训练且参数固定。特别地，我们假设我们已经学习了K个聚合器函数的参数（表示为AGGREGATEk，∀K∈ {1，…，K}），它聚合来自节点邻居的信息以及一组权重矩阵Wk，∀K∈ {1，…，K}，用于在模型的不同层或“搜索深度”之间传播信息。第3.2节描述了我们如何训练这些参数。

