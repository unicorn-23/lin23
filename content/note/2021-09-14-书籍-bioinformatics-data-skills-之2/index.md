---
title: 书籍-《Bioinformatics-Data-Skills》之2
author: Lin Gui
date: '2021-09-14'
categories:
  - 学习
tags:
  - 书籍
slug: 书籍-bioinformatics-data-skills-之二
---

草草地看了一下这本书part1的内容，大概讲了生信科研相关的，例如生信的发展，生信研究的好处等等，还讲述了些代码相关的注意事项，很快的过了一遍，没什么大意思，记得书中加大加粗的生信科研**黄金法则**：**Never ever trust your tools or data**。

好的，我们来看一下part2。

### part2：开始生物信息学项目。

正如一个组织良好的实验室使科学家的生活更轻松一样，一个组织良好、记录良好的项目使生物信息学家的生活更轻松。不管你正在做的项目是什么，你的项目目录应该以一种一致的和可理解的方式来安排。清晰的项目组织使您和合作者更容易准确地找出所有内容的位置和内容。此外，当文件被组织起来并清楚地命名时，自动化任务会容易得多。例如，如果将存储在单独FASTA文件中的300个基因序列组织在一个目录中，并统一命名，则使用脚本处理这些基因序列非常简单。

每一个生物信息学项目都是从一个空的项目目录开始的，所以这本书以一个关于项目组织的章节开始是合适的。在本章中，我们将介绍一些组织生物信息学项目目录的最佳实践，以及如何使用纯文本标记文件以数字方式记录您的工作。我们还将了解为什么项目目录组织不仅仅是为了保持整洁，而且对于跨大量文件自动执行任务的方式至关重要（我们在生物信息学中经常这样做）。

### **项目目录和目录结构**

创建一个组织有序的目录结构是一个可重复的生物信息学项目的基础。实际的过程非常简单：规划一个项目只需要使用mkdir创建几个目录，并使用touch创建空的自述文件（我们将在后面更深入地了解这些命令）。但这种简单的初步规划从长远来看是值得的。对于大型项目，研究人员可以花数年时间在这个指导结构中工作。其他研究人员也注意到了良好项目组织的重要性（Noble 2009）。虽然最终您将制定一个适合您的项目组织方案，但在本章中，我们将从我在工作中使用的方案开始（与Noble的方案类似）。

项目中使用的所有文件和目录都应位于一个具有明确名称的项目目录中。在项目过程中，您将积累大量的数据文件、笔记、脚本等。如果这些文件、笔记、脚本分散在您的硬盘上（或者更糟的是，分散在许多计算机的硬盘上），那么跟踪每一件事情将是一场噩梦。更糟糕的是，这样一个杂乱无章的项目会让你的研究几乎无法重现。

将所有文件保存在一个目录中将大大简化您和您的合作者的工作，并促进可复制性（我们将在第5章讨论如何使用Git协作处理项目目录）。假设您正在进行SNP调用玉米（Zea mays）。第一步是选择一个简短、适当的项目名称并创建一些基本目录：

```
mkdir data
makir data/seqs scripts analysis
#这里创建3个文件夹分别存储3类文件。
```

这是一个合理的项目布局方案。这里，data/包含所有原始和中间数据。正如我们将看到的，数据处理步骤在此数据/目录中被视为单独的子项目。我将常规项目范围的脚本保存在脚本/目录中。如果脚本包含许多文件（例如，多个Python模块），那么它们应该位于自己的子目录中。在开发这些脚本时（当脚本生成测试输出文件时），将脚本隔离在它们自己的子目录中还可以保持项目目录整洁。

生物信息学项目包含许多较小的分析，例如，分析原始序列的质量、对齐器输出以及最终数据，这些数据将生成论文的图表。我更喜欢将它们保存在单独的分析/目录中，因为它允许协作者查看这些高级分析，而无需深入挖掘子项目目录。

脚本和分析通常需要引用项目层次结构中的其他文件（如数据）。这可能需要引用目录层次结构中的父目录（例如，带..）。在这些情况下，始终使用相对路径（例如，../data/stats/qual.txt）而不是绝对路径（例如，/home/vinceb/projects/zmais snps/data/stats/qual.txt）非常重要。只要内部项目目录结构保持不变，这些相对路径将始终有效。相反，绝对路径依赖于项目目录级别以上的特定用户帐户和目录结构细节（不好）。使用绝对路径会降低您的工作在协作者之间的可移植性，并降低再现性。

这里我的项目目录方案绝不是唯一可能的方案。我曾与生物信息学家合作，他们在项目中使用完全不同的方案，并做了出色的工作。然而，不管组织结构如何，一个好的生物信息学家总是会广泛地记录所有内容，并使用计算机可以解析的清晰文件名，这两点我们将在稍后讨论。

### **项目文件**

除了有一个组织良好的目录结构，你的生物信息学项目也应该有很好的文档记录。不良的文档记录可能导致不可生产性和严重错误。生物信息学工作中存在大量潜在的复杂性：复杂的工作流、多个文件、无数的程序参数和不同的软件版本。防止这种复杂性引发问题的最佳方法是广泛地记录所有内容。当您需要返回并重新运行分析、编写有关论文步骤的详细方法或在目录中查找某些数据的来源时，文档还可以使您的生活更轻松。那么你到底应该记录什么呢？以下是一些想法：

***记录您的方法和工作流程***

这应该包括在shell中运行的完整命令行（复制和粘贴），这些命令行生成数据或中间结果。即使在软件中使用默认值，也要确保记下这些值；程序的后续版本可能会使用不同的默认值。脚本自然会记录所有步骤和参数（我们将在第12章中介绍这一主题），但一定要记录用于运行此脚本的任何命令行选项。通常，任何产生工作中使用的结果的命令都需要记录在某个地方。

***记录项目目录中所有数据的来源***

您需要跟踪数据从何处下载、谁给了您以及任何其他相关信息。“数据”不仅仅指项目的实验数据，它是程序用来创建输出的任何数据。这包括您的合作者从各自的分析、基因注释轨迹、参考基因组等发送给您的文件。记录有关您的数据或元数据的重要数据至关重要。例如，如果您下载了一组基因区域，请记录网站的URL。这似乎是一个显而易见的建议，但我无数次遇到一个分析步骤，因为有人忘了记录数据的来源而无法轻松复制。

***下载数据时记录***

重要的是要包括数据下载的时间，因为外部数据源（如网站或服务器）将来可能会更改。例如，如果在外部数据库更新后重新运行直接从数据库下载数据的脚本，可能会产生不同的结果。因此，记录数据何时进入存储库非常重要。

***记录数据版本信息***

许多数据库都有明确的版本号、版本号或名称（例如，拟南芥基因组注释的TAIR10版本，或秀丽隐杆线虫的Wormbase版本WS231）。在文档中记录所有版本信息非常重要，包括次要版本号。

***描述您是如何下载数据的***

例如，您是否使用MySQL下载了一组基因？还是UCSC基因组浏览器？这些详细信息有助于跟踪协作者之间的数据差异等问题。

***记录您运行的软件版本***

这似乎不重要，但请记住第6页“可复制研究”中的一个例子，我的同事和我将不一致的结果追溯到一个正在更新的软件。这些细节很重要。好的BioInformatics软件通常有一个命令行选项来返回当前版本。使用版本控制系统（如Git）管理的软件对每个版本都有明确的标识，可用于记录您运行的精确版本（我们将在第5章了解更多信息）。如果没有可用的版本信息，发布日期、软件链接和下载日期就足够了。

所有这些信息最好存储在纯文本自述文件中。纯文本可以轻松地从命令行直接读取、搜索和编辑，这使它成为可移植和可访问自述文件的完美选择。它也可以在所有计算机系统上使用，这意味着您可以在服务器或计算机集群上直接记录您的步骤。纯文本还缺少复杂的格式，这会在将文档中的命令复制和粘贴回命令行时产生问题。最好避免像Microsoft Word for README Documentation这样的格式，因为这些格式对于生物信息学中常见的Unix系统的可移植性较差。

您应该将自述文件保存在哪里？一个好方法是将自述文件保存在项目的每个主目录中。这些自述文件不一定需要很长，但它们至少应该解释这个目录中有什么以及它是如何到达那里的。即使是这个小小的努力也可以节省一些人浏览项目目录的大量时间，并防止混淆。这个人可能是你的顾问或合作者，可能是你搬到另一个实验室后试图复制你的工作的同事，也可能是你六个月后完全忘记自己做了什么的自己（每个人都会这样！）。

例如，数据/自述文件将包含有关数据/目录中数据文件的元数据。即使您认为您可以记住有关数据的所有相关信息，也可以将其放入自述文件中（合作者不必通过电子邮件向您询问文件是什么或在哪里）。让我们使用touch创建一些空的自述文件。touch可更新文件或文件的修改时间，如果文件不存在，则创建该文件。我们可以将其用于后一个目的，以创建空模板文件来布置项目结构：

```
$touch README data/README
```

按照刚才讨论的文档指南，此data/readme文件将包括您在data/中下载数据的位置、下载时间以及方式。当我们在第6章中了解更多关于数据的信息时，我们将看到一个案例研究示例，说明如何在项目目录中下载并正确记录数据（“案例研究：可复制下载数据”，第120页）。

通过记录这些信息，我们可以记录我们的实验和分析的所有内容，使其具有可复制性。请记住，随着项目的增长和数据文件的积累，为了您自己的理智而跟踪它也是值得的。

### 小结

好的，看了一下前两篇的译文，第一部分主要讲述了项目文件该有效的划分，以便以后的迁移、重现、合作等。后3部分看目录讲述了使用unix，远程连接，github，对着三部分不感兴趣，原因是已有ssh链接Linux服务器，github使用的经验，故不深入研究。

来看一下第6部分：Bioinformatics Data

### 生物信息学的数据

到目前为止，我们已经介绍了生物信息学入门的许多预备知识：组织项目目录、中间Unix、使用远程机器以及使用版本控制。然而，我们忽略了一个新的生物信息学项目的一个重要组成部分：数据。

数据是任何生物信息学项目的必要条件。通过提炼大量数据，我们可以从中提取信息，从而进一步理解复杂的生物系统。不幸的是，对于基因组学中常见的大型复杂数据集来说，许多简单的中小型数据集任务是一个挑战。这些挑战包括：

***检索数据***

无论是下载大型测序数据集还是访问web应用程序数百次以下载特定文件，在生物信息学中检索数据都需要特殊的工具和技能。

***确保数据完整性***

跨网络传输大型数据集会带来更多数据损坏的机会，这可能会导致不正确的分析。因此，在继续分析之前，我们需要使用工具确保数据完整性。同样的工具也可用于验证我们在分析中使用的数据版本是否正确。

***压缩***

我们在生物信息学中使用的数据非常大，常常需要压缩。因此，处理压缩数据是生物信息学中的一项基本技能。

### 检索生物信息学数据

假设您刚刚被告知项目的排序已经完成：您有六条Illumina数据通道可从排序中心下载。通过web浏览器下载如此数量的数据是不可行的：web浏览器不是为下载如此大的数据集而设计的。此外，您需要将这些排序数据下载到您的服务器，而不是您浏览互联网的本地工作站。要做到这一点，您需要使用SSH连接到数据处理服务器，并使用命令行工具将数据直接下载到这台机器上。在本节中，我们将介绍其中的一些工具。

**使用wget和curl下载数据**

从Web下载数据的两个常用命令行程序是wget和curl。根据您的系统，这些可能尚未安装；您必须使用软件包管理器安装它们（例如，自制软件或apt get）。虽然curl和wget在基本功能上相似，但它们的相对优势却大不相同，因此我经常使用这两种方法。

**wget**

wget可用于从命令行快速下载文件，例如，从GRCh37（也称为hg19）程序集版本下载人类染色体22：

```
$wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/chromosomes/chr22.fa.gz --2013-06-30 00:15:45-- http://[...]/goldenPath/hg19/chromosomes/chr22.fa.gz Resolving hgdownload.soe.ucsc.edu... 128.114.119.163
Connecting to hgdownload.soe.ucsc.edu|128.114.119.163|:80... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 11327826 (11M) [application/x-gzip]
    Saving to: ‘chr22.fa.gz’
    17% [======>                                ] 1,989,172    234KB/s  eta 66s
```

wget将此文件下载到当前目录，并提供有用的进度指示器。请注意，到染色体22的链接以“http”（超文本传输协议的缩写）开头。wget还可以处理FTP链接（以“FTP”开头，是文件传输协议的缩写）。一般来说，对于大型文件，FTP比HTTP更可取（UCSC Genome Browser等网站经常推荐FTP）。

因为UCSC慷慨地公开提供人类参考基因组，我们不需要任何身份验证就可以访问该文件。但是，如果您从实验室信息管理系统（LIMS）下载数据，可能需要首先使用用户名和密码进行身份验证。对于简单的HTTP或FTP身份验证，您可以使用wget的--user=和--ask密码选项进行身份验证。一些网站使用更复杂的认证程序；在这种情况下，您需要与站点管理员联系。

wget的优点之一是它可以递归地下载数据。当使用递归选项（--recursive或-r）运行时，wget还将跟踪并下载链接到的页面，甚至跟踪并下载这些页面上的链接，以此类推。默认情况下（为了避免下载整个互联网），wget将自身限制为只跟踪五个深度的链接（但可以使用选项--level或-l进行自定义）。

递归下载可用于从页面下载特定类型的所有文件。例如，如果另一个实验室的网页包含许多我们希望下载的GTF文件，我们可以使用：

```
$wget --accept ""*.gtf" --no--directories --recursive --no-parent \
http://genomics.someuniversity.edu/labsite/annotation.html
```

但要当心！wget的递归下载可能非常具有攻击性。如果不受限制，wget将在--level设置的最大深度内下载它可以达到的所有内容。在前面的示例中，我们以两种方式限制wget：使用--no parent阻止wget下载目录结构中较高的页面，以及使用--accept“*.gtf”，它只允许wget下载与此模式匹配的文件名。

使用wget的递归选项时要小心；它可以利用大量的网络资源，并使远程服务器过载。在某些情况下，如果您下载太多或太快，远程主机可能会阻止您的IP地址。如果您计划从远程主机下载大量数据，最好向网站的sysad-min查询建议的下载限制，这样您的IP就不会被阻止。wget的--limit-rate选项可用于限制wget下载文件的速度。

wget是一个非常强大的工具；前面的例子只触及了其能力的表面。一些常用选项见表6-1，详细列表见man wget。

表6-1见书去，p111。

**curl**

curl的用途与wget略有不同。wget非常适合通过HTTP或FTP下载文件，并使用其递归选项从网页中抓取数据。curl的行为类似，尽管默认情况下会将文件写入标准输出。要像下载wget一样下载22号染色体，我们将使用：

```
$ curl http://[...]/goldenPath/hg19/chromosomes/chr22.fa.gz > chr22.fa.gz
% Total % Received % Xferd Average Speed Time Time Time Current
                                     Dload  Upload   Total   Spent    Left  Speed
     14 10.8M   14 1593k    0     0   531k      0  0:00:20  0:00:02  0:00:18  646k

```

请注意，我必须截断URL，以便此示例适合页面；URL与我们之前使用的wget相同。

如果不希望重定向curl的输出，请使用-O<filename>将结果写入<filename>。如果省略filename参数，curl将使用与远程主机相同的文件名。

curl的优点是它可以使用比wget更多的协议传输文件，包括SFTP（安全FTP）和SCP（安全拷贝）。curl的一个特别好的特性是，如果启用了-L/--location选项，它可以跟踪页面重定向。启用此选项后，curl将下载链接重定向到的最终页面，而不是redi-rect页面本身。最后，Curl本身也是一个库，这意味着除了命令行Curl程序外，Curl的功能还由软件库包装，如RCurl和pycurl。

**Rsync和安全拷贝（scp）**

wget和curl适合于从命令行快速下载文件，但对于一些较重的任务来说并不理想。例如，假设一位同事需要项目目录中所有被Git忽略的大型序列数据集（例如，在.gitignore中）。在网络上同步这些完整目录的更好工具是Rsync。

出于以下几个原因，Rsync对于这些类型的任务是一个更好的选择。首先，Rsync通常更快，因为它只发送文件版本之间的差异（当副本已经存在或部分存在时），并且可以在传输过程中压缩文件。其次，Rsync有一个存档选项，可以保留链接、修改时间戳、权限、所有权和其他文件属性。这使得Rsync成为整个目录的网络备份的最佳选择。Rsync还具有许多功能和选项来处理不同的备份方案，例如，如果远程主机上存在文件，该怎么办。

rsync的基本语法是**rsync source destination**。其中source是要复制的文件或目录的源，destination是要将这些文件复制到的目标。源或目标都可以是格式中指定的远程主机user@host：/path/to/directory/。

让我们看一个例子，说明如何使用rsync将整个目录复制到另一台机器上。假设您希望将zea_mays/data中的所有项目数据复制到主机192.168.237.42上同事的目录/home/deborah/zea_mays/data中。

用于复制整个目录的rsync选项的最常见组合是-avz。选项-a启用wrsync的归档模式，-z启用文件传输压缩，-v使rsync的进度更加详细，以便您可以查看正在传输的内容，因为我们将通过SSH连接到远程主机，所以我们还需要使用-e SSH。

我们的目录复制命令如下所示：

```
$ rsync -avz -e ssh zea_mays/data/ vinceb@[...]:/home/deborah/zea_mays/data
building file list ... done
zmaysA_R1.fastq
zmaysA_R2.fastq
zmaysB_R1.fastq
zmaysB_R2.fastq
zmaysC_R1.fastq
zmaysC_R2.fastq
sent 2861400 bytes  received 42 bytes  107978.94 bytes/sec
total size is 8806085  speedup is 3.08
```

rsync的一个微妙但重要的行为是，在rsync中指定路径时，尾部斜杠（例如，data/versusdata）是有意义的。源路径中的尾随斜杠表示复制源目录的内容，而没有尾随斜杠表示复制整个目录本身。因为我们想在我们的示例中复制zea_mays/data/到/home/deborah/zea_mays/data的所有内容，所以我们使用了一个尾部斜杠。如果远程目标主机上不存在数据/目录，我们希望使用zea_mays/data（例如，省略尾部斜杠）复制它及其内容。

由于rsync仅在文件不存在或已更改时传输文件，因此您可以（而且应该）在文件传输后再次运行rsync。这是一个简单的检查，以确保两个目录之间的所有内容都是同步的。在脚本中调用rsync时，最好检查rsync的退出状态；如果在传输文件时遇到问题，rsync将以非零状态退出。最后，rsync可以使用SSH配置文件中指定的主机别名（请参阅第57页“使用SSH连接到远程机器”中的第一个技巧）。如果通过ssh主机别名连接到主机，则可以省略-e ssh。

有时，我们只需要通过SSH快速复制单个文件，以执行Unix的cp就足够了，但需要通过SSH连接工作的任务。rsync可以工作，但有点过头了。安全副本（scp）非常适合此用途。Secure copy的工作原理与cp类似，只是我们需要同时指定主机和路径（使用相同的user@host：/path/to/file表示法为wget）。例如，我们可以使用以下方式将单个GTF文件传输到192.168.237.42:/home/deborah/zea_mays/data/：

```
$ scp Zea_mays.AGPv3.20.gtf 192.168.237.42:/home/deborah/zea_mays/data/
Zea_mays.AGPv3.20.gtf 100% 55 0.1KB/s 00:00
```

### 小结

这一部分介绍了如何从网上下载数据到自己的服务器，四个方法wget、curl、rsync、scp。这一部分的剩下内容主要讲数据的压缩和安全性，暂时不感兴趣。开一节新的来看一下part3。
